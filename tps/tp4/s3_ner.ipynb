{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'entités nommées avec SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation est accessible ici: https://spacy.io/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Requirement already satisfied: spacy in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (0.20.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (2.3.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: wrapt in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fr-core-news-md in c:\\users\\balda\\onedrive\\bureau\\tac\\tac\\tac_venv\\lib\\site-packages (3.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n",
    "%pip install fr-core-news-md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
      "     ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/45.8 MB 100.9 kB/s eta 0:07:35\n",
      "     --------------------------------------- 0.0/45.8 MB 100.9 kB/s eta 0:07:35\n",
      "     --------------------------------------- 0.0/45.8 MB 115.5 kB/s eta 0:06:37\n",
      "     --------------------------------------- 0.0/45.8 MB 115.5 kB/s eta 0:06:37\n",
      "     --------------------------------------- 0.1/45.8 MB 148.8 kB/s eta 0:05:08\n",
      "     --------------------------------------- 0.1/45.8 MB 148.8 kB/s eta 0:05:08\n",
      "     --------------------------------------- 0.1/45.8 MB 148.8 kB/s eta 0:05:08\n",
      "     --------------------------------------- 0.1/45.8 MB 266.2 kB/s eta 0:02:52\n",
      "     --------------------------------------- 0.3/45.8 MB 563.8 kB/s eta 0:01:21\n",
      "      --------------------------------------- 0.9/45.8 MB 1.5 MB/s eta 0:00:30\n",
      "     - -------------------------------------- 1.6/45.8 MB 2.5 MB/s eta 0:00:18\n",
      "     - -------------------------------------- 2.1/45.8 MB 3.0 MB/s eta 0:00:15\n",
      "     -- ------------------------------------- 3.3/45.8 MB 4.5 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 4.1/45.8 MB 5.2 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 4.8/45.8 MB 5.8 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 5.6/45.8 MB 6.5 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 6.3/45.8 MB 6.9 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 7.1/45.8 MB 7.4 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 7.8/45.8 MB 7.8 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 8.4/45.8 MB 8.0 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 9.2/45.8 MB 8.5 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 10.2/45.8 MB 9.0 MB/s eta 0:00:04\n",
      "     --------- ----------------------------- 10.9/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "     --------- ----------------------------- 11.5/45.8 MB 17.2 MB/s eta 0:00:02\n",
      "     --------- ----------------------------- 11.5/45.8 MB 17.2 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 12.9/45.8 MB 16.8 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 13.4/45.8 MB 16.8 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 14.9/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 15.6/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 16.3/45.8 MB 17.3 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 17.4/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 18.1/45.8 MB 18.7 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 18.8/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 19.4/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 20.1/45.8 MB 17.2 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 20.7/45.8 MB 16.4 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 21.2/45.8 MB 17.2 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 22.0/45.8 MB 18.2 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 22.7/45.8 MB 17.2 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 23.2/45.8 MB 17.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 24.1/45.8 MB 17.3 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 24.5/45.8 MB 16.4 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 25.1/45.8 MB 15.6 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 26.1/45.8 MB 16.0 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 26.7/45.8 MB 15.6 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 27.4/45.8 MB 15.6 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 28.2/45.8 MB 15.2 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 28.8/45.8 MB 14.9 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 29.5/45.8 MB 14.9 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 30.2/45.8 MB 15.2 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 30.8/45.8 MB 15.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 31.5/45.8 MB 15.2 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 32.1/45.8 MB 14.9 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 32.8/45.8 MB 14.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 33.6/45.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 34.3/45.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 35.0/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 35.6/45.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 36.3/45.8 MB 15.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 37.0/45.8 MB 15.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 37.8/45.8 MB 15.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 38.5/45.8 MB 15.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 39.1/45.8 MB 15.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 39.9/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 40.6/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 41.3/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 41.9/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 42.7/45.8 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 43.4/45.8 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 44.1/45.8 MB 16.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  44.8/45.8 MB 16.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.5/45.8 MB 16.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.8/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.8/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.8/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.8/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.8/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 45.8/45.8 MB 11.7 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
=======
      "Requirement already satisfied: fr_core_news_md in /home/max/git/tac/venv/lib/python3.11/site-packages (3.8.0)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "%pip install  fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple sur un corpus de test fourni par SpaCy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " \"Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\",\n",
       " \"San Francisco envisage d'interdire les robots coursiers sur les trottoirs\",\n",
       " 'Londres est une grande ville du Royaume-Uni',\n",
       " 'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe',\n",
       " \"Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon\",\n",
       " \"La France ne devrait pas manquer d'électricité cet été, même en cas de canicule\",\n",
       " 'Nouvelles attaques de Trump contre le maire de Londres',\n",
       " 'Où es-tu ?',\n",
       " 'Qui est le président de la France ?',\n",
       " 'Où est la capitale des États-Unis ?',\n",
       " 'Quand est né Barack Obama ?']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 4,
=======
     "execution_count": 3,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le corpus de Spacy\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 4,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 4,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isoler la première phrase\n",
    "sent = sentences[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 5,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter la phrase avec Spacy\n",
    "doc = nlp(sent)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 6,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 6,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 7,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 8,
=======
     "execution_count": 7,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 8,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " 'ents': [{'start': 0, 'end': 5, 'label': 'ORG'}],\n",
       " 'sents': [{'start': 0, 'end': 72}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 5,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': 'Gender=Masc|Number=Sing',\n",
       "   'lemma': 'Apple',\n",
       "   'dep': 'nsubj',\n",
       "   'head': 1},\n",
       "  {'id': 1,\n",
       "   'start': 6,\n",
       "   'end': 13,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "   'lemma': 'cherche',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 1},\n",
       "  {'id': 2,\n",
       "   'start': 14,\n",
       "   'end': 15,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'à',\n",
       "   'dep': 'mark',\n",
       "   'head': 3},\n",
       "  {'id': 3,\n",
       "   'start': 16,\n",
       "   'end': 23,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'VerbForm=Inf',\n",
       "   'lemma': 'acheter',\n",
       "   'dep': 'xcomp',\n",
       "   'head': 1},\n",
       "  {'id': 4,\n",
       "   'start': 24,\n",
       "   'end': 27,\n",
       "   'tag': 'DET',\n",
       "   'pos': 'DET',\n",
       "   'morph': 'Definite=Ind|Gender=Fem|Number=Sing|PronType=Art',\n",
       "   'lemma': 'un',\n",
       "   'dep': 'det',\n",
       "   'head': 5},\n",
       "  {'id': 5,\n",
       "   'start': 28,\n",
       "   'end': 33,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'start',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 6,\n",
       "   'start': 33,\n",
       "   'end': 34,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': '',\n",
       "   'lemma': '-',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 7,\n",
       "   'start': 34,\n",
       "   'end': 36,\n",
       "   'tag': 'X',\n",
       "   'pos': 'X',\n",
       "   'morph': '',\n",
       "   'lemma': 'up',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 8,\n",
       "   'start': 37,\n",
       "   'end': 45,\n",
       "   'tag': 'ADJ',\n",
       "   'pos': 'ADJ',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'anglais',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 9,\n",
       "   'start': 46,\n",
       "   'end': 50,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'pour',\n",
       "   'dep': 'case',\n",
       "   'head': 11},\n",
       "  {'id': 10,\n",
       "   'start': 51,\n",
       "   'end': 52,\n",
       "   'tag': 'NUM',\n",
       "   'pos': 'NUM',\n",
       "   'morph': 'NumType=Card',\n",
       "   'lemma': '1',\n",
       "   'dep': 'nummod',\n",
       "   'head': 11},\n",
       "  {'id': 11,\n",
       "   'start': 53,\n",
       "   'end': 61,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|NumType=Card|Number=Sing',\n",
       "   'lemma': 'milliard',\n",
       "   'dep': 'obl:mod',\n",
       "   'head': 3},\n",
       "  {'id': 12,\n",
       "   'start': 62,\n",
       "   'end': 64,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'de',\n",
       "   'dep': 'case',\n",
       "   'head': 13},\n",
       "  {'id': 13,\n",
       "   'start': 65,\n",
       "   'end': 72,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|Number=Plur',\n",
       "   'lemma': 'dollar',\n",
       "   'dep': 'nmod',\n",
       "   'head': 11}]}"
      ]
     },
<<<<<<< HEAD
     "execution_count": 9,
=======
     "execution_count": 8,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.to_json()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 9,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars' contient les entités suivantes : Apple (ORG)\n",
      "'Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs' ne contient aucune entité\n",
      "'San Francisco envisage d'interdire les robots coursiers sur les trottoirs' contient les entités suivantes : San Francisco (LOC)\n",
      "'Londres est une grande ville du Royaume-Uni' contient les entités suivantes : Londres (LOC), Royaume-Uni (LOC)\n",
      "'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe' contient les entités suivantes : L’Italie (LOC), ArcelorMittal (ORG), Europe (LOC)\n",
      "'Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon' contient les entités suivantes : Apple (ORG), HomePod (MISC), Echo (ORG), Amazon (ORG)\n",
      "'La France ne devrait pas manquer d'électricité cet été, même en cas de canicule' contient les entités suivantes : La France (LOC)\n",
      "'Nouvelles attaques de Trump contre le maire de Londres' contient les entités suivantes : Nouvelles attaques de (MISC), Trump (PER), Londres (LOC)\n",
      "'Où es-tu ?' ne contient aucune entité\n",
      "'Qui est le président de la France ?' contient les entités suivantes : la France (LOC)\n",
      "'Où est la capitale des États-Unis ?' contient les entités suivantes : États-Unis (LOC)\n",
      "'Quand est né Barack Obama ?' contient les entités suivantes : Barack Obama (PER)\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le test sur toutes les phrases\n",
    "for sent in sentences:\n",
    "    doc = nlp(sent)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append(f\"{ent.text} ({ent.label_})\")\n",
    "    if entities:\n",
    "        print(f\"'{doc.text}' contient les entités suivantes : {', '.join(entities)}\")\n",
    "    else:\n",
    "        print(f\"'{doc.text}' ne contient aucune entité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la reconnaissance d'entités nommées sur notre corpus"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 10,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le texte\n",
    "n=1000000\n",
    "text = open(\"../data/all.txt\", encoding='utf-8').read()[:n]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 11,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: total: 57.4 s\n",
      "Wall time: 59 s\n"
=======
      "CPU times: user 24.7 s, sys: 1.04 s, total: 25.7 s\n",
      "Wall time: 26 s\n"
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Traiter le texte\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 12,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les entités\n",
    "people = defaultdict(int)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 13,
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Congo</kw apparait 169 fois dans le corpus\n",
      "M. Lumumba apparait 121 fois dans le corpus\n",
      "O. N. U. apparait 53 fois dans le corpus\n",
      "M. Eyskens apparait 49 fois dans le corpus\n",
      "Katanga apparait 37 fois dans le corpus\n",
      "Lumumba apparait 31 fois dans le corpus\n",
      "M. Tshombe apparait 30 fois dans le corpus\n",
      "M. Wigny apparait 29 fois dans le corpus\n",
      "A.F.P. apparait 25 fois dans le corpus\n",
      "M. Hammarskjôld apparait 23 fois dans le corpus\n",
      "Elisabethville apparait 21 fois dans le corpus\n",
      "M. Kasavubu apparait 19 fois dans le corpus\n",
      "A. P. apparait 17 fois dans le corpus\n",
      "Patrice Lumumba apparait 16 fois dans le corpus\n",
      "Eyskens apparait 16 fois dans le corpus\n",
      "A. F. P. apparait 15 fois dans le corpus\n",
      "Wigny apparait 14 fois dans le corpus\n",
      "C. M. P. apparait 14 fois dans le corpus\n",
      "M. Kanza apparait 12 fois dans le corpus\n",
      "général de Gaulle apparait 12 fois dans le corpus\n",
      "Léopold II apparait 12 fois dans le corpus\n",
      "Gilson apparait 12 fois dans le corpus\n",
      "Tshombe apparait 11 fois dans le corpus\n",
      "M. Lefèvre apparait 10 fois dans le corpus\n",
      "MM. Kasavubu apparait 10 fois dans le corpus\n",
      "Sodée apparait 10 fois dans le corpus\n",
      "M. Kashamura apparait 9 fois dans le corpus\n",
      "Ganshof van der Meersch apparait 9 fois dans le corpus\n",
      "P. S. C. apparait 9 fois dans le corpus\n",
      "M. Merchiers apparait 9 fois dans le corpus\n",
      "Selwyn Lloyd apparait 9 fois dans le corpus\n",
      "M. De Schryver apparait 9 fois dans le corpus\n",
      "C. M. P apparait 9 fois dans le corpus\n",
      "M. Ganshof van der Meersch apparait 8 fois dans le corpus\n",
      "Hammarskjôld apparait 8 fois dans le corpus\n",
      "Kamina apparait 8 fois dans le corpus\n",
      "M. « H apparait 8 fois dans le corpus\n",
      "général Janssens apparait 8 fois dans le corpus\n",
      "De Schryver apparait 8 fois dans le corpus\n",
      "M. Gilson apparait 8 fois dans le corpus\n",
      "M. Tshombé apparait 8 fois dans le corpus\n",
      "Eastman Kodak apparait 8 fois dans le corpus\n",
      "président Kasavubu apparait 7 fois dans le corpus\n",
      "Tordre apparait 7 fois dans le corpus\n",
      "M. Khrouchtchev apparait 7 fois dans le corpus\n",
      "Théo Lefèvre apparait 7 fois dans le corpus\n",
      "M. Motz apparait 7 fois dans le corpus\n",
      "Président apparait 7 fois dans le corpus\n",
      "M. Gizenga apparait 7 fois dans le corpus\n",
      "von Horn apparait 7 fois dans le corpus\n"
=======
      "Thérèse apparait 28 fois dans le corpus\n",
      "Guilbert apparait 22 fois dans le corpus\n",
      "M. Wilson apparait 20 fois dans le corpus\n",
      "Daubrac apparait 20 fois dans le corpus\n",
      "Gioconda apparait 19 fois dans le corpus\n",
      "Rossel apparait 19 fois dans le corpus\n",
      "Enguerrand apparait 17 fois dans le corpus\n",
      "Wilson apparait 15 fois dans le corpus\n",
      "Molière apparait 15 fois dans le corpus\n",
      "Parentis apparait 13 fois dans le corpus\n",
      "Edwige apparait 13 fois dans le corpus\n",
      "Savinien apparait 13 fois dans le corpus\n",
      "Octave apparait 12 fois dans le corpus\n",
      "Monsieur apparait 12 fois dans le corpus\n",
      "Grippe-Soleil apparait 11 fois dans le corpus\n",
      "duc d’Aumale apparait 11 fois dans le corpus\n",
      "Réclames apparait 10 fois dans le corpus\n",
      "Reine apparait 10 fois dans le corpus\n",
      "Ambassadeurs apparait 10 fois dans le corpus\n",
      "Jules Ferry apparait 9 fois dans le corpus\n",
      "Monseigneur apparait 9 fois dans le corpus\n",
      "Agence Rossel apparait 8 fois dans le corpus\n",
      "Henri apparait 8 fois dans le corpus\n",
      "Finet apparait 7 fois dans le corpus\n",
      "M. Graux apparait 7 fois dans le corpus\n",
      "Ali-Baba apparait 7 fois dans le corpus\n",
      "M. Vigneau apparait 7 fois dans le corpus\n",
      "M. Van Praet apparait 7 fois dans le corpus\n",
      "Aubertin apparait 6 fois dans le corpus\n",
      "Roux apparait 6 fois dans le corpus\n",
      "Marguerite apparait 6 fois dans le corpus\n",
      "Simon apparait 6 fois dans le corpus\n",
      "Bonhomme apparait 5 fois dans le corpus\n",
      "prince Baudouin apparait 5 fois dans le corpus\n",
      "Beernaert apparait 5 fois dans le corpus\n",
      "M. Finet apparait 5 fois dans le corpus\n",
      "Cockerill apparait 5 fois dans le corpus\n",
      "P Soc apparait 5 fois dans le corpus\n",
      "Charl apparait 5 fois dans le corpus\n",
      "Meyer apparait 5 fois dans le corpus\n",
      "Propriétaires apparait 5 fois dans le corpus\n",
      "Pollet apparait 5 fois dans le corpus\n",
      "Ponchielli apparait 5 fois dans le corpus\n",
      "Daubiehon apparait 5 fois dans le corpus\n",
      "Louvel apparait 4 fois dans le corpus\n",
      "Mme X. apparait 4 fois dans le corpus\n",
      "Joseph Bonhomme apparait 4 fois dans le corpus\n",
      "Beethoven apparait 4 fois dans le corpus\n",
      "Blanchisserie apparait 4 fois dans le corpus\n",
      "Jules Verne apparait 4 fois dans le corpus\n"
>>>>>>> 693dd33278dc5584c1567a6eadc54d069df50106
     ]
    }
   ],
   "source": [
    "# Trier et imprimer\n",
    "\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for person, freq in sorted_people[:50]:\n",
    "    print(f\"{person} apparait {freq} fois dans le corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: essayez de lister les lieux (LOC) et les organisations (ORG) les plus mentionnées dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nations Unies apparaît 112 fois dans le corpus\n",
      "Conseil apparaît 95 fois dans le corpus\n",
      "O.N.U. apparaît 79 fois dans le corpus\n",
      "Conseil de sécurité apparaît 63 fois dans le corpus\n",
      "DU</kw apparaît 46 fois dans le corpus\n",
      "Sabena apparaît 44 fois dans le corpus\n",
      "Chambre apparaît 42 fois dans le corpus\n",
      "Blancs apparaît 37 fois dans le corpus\n",
      "ministre des Affaires étrangères apparaît 36 fois dans le corpus\n",
      "Sénat apparaît 28 fois dans le corpus\n"
     ]
    }
   ],
   "source": [
    "# Compter les organisations (ORG)\n",
    "orgs = defaultdict(int)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"ORG\" and len(ent.text) > 3:\n",
    "        orgs[ent.text] += 1\n",
    "\n",
    "# Trier et afficher les 10 organisations les plus fréquentes\n",
    "sorted_orgs = sorted(orgs.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for org, freq in sorted_orgs[:10]:\n",
    "    print(f\"{org} apparaît {freq} fois dans le corpus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congo</kw apparaît 988 fois dans le corpus\n",
      "Belgique apparaît 332 fois dans le corpus\n",
      "Katanga apparaît 207 fois dans le corpus\n",
      "Léopoldville apparaît 171 fois dans le corpus\n",
      "Belges apparaît 123 fois dans le corpus\n",
      "Bruxelles apparaît 112 fois dans le corpus\n",
      "Etat apparaît 99 fois dans le corpus\n",
      "Afrique apparaît 97 fois dans le corpus\n",
      "République apparaît 74 fois dans le corpus\n",
      "Etats-Unis apparaît 74 fois dans le corpus\n"
     ]
    }
   ],
   "source": [
    "# Compter les lieux (LOC)\n",
    "places = defaultdict(int)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\" and len(ent.text) > 3:\n",
    "        places[ent.text] += 1\n",
    "\n",
    "# Trier et afficher les 10 lieux les plus fréquents\n",
    "sorted_places = sorted(places.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for place, freq in sorted_places[:10]:\n",
    "    print(f\"{place} apparaît {freq} fois dans le corpus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congo</kw apparaît 169 fois dans le corpus\n",
      "M. Lumumba apparaît 121 fois dans le corpus\n",
      "O. N. U. apparaît 53 fois dans le corpus\n",
      "M. Eyskens apparaît 49 fois dans le corpus\n",
      "Katanga apparaît 37 fois dans le corpus\n",
      "Lumumba apparaît 31 fois dans le corpus\n",
      "M. Tshombe apparaît 30 fois dans le corpus\n",
      "M. Wigny apparaît 29 fois dans le corpus\n",
      "A.F.P. apparaît 25 fois dans le corpus\n",
      "M. Hammarskjôld apparaît 23 fois dans le corpus\n"
     ]
    }
   ],
   "source": [
    "# Compter les personnes (PER)\n",
    "people = defaultdict(int)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1\n",
    "\n",
    "# Trier et imprimer\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for person, freq in sorted_people[:10]:\n",
    "    print(f\"{person} apparaît {freq} fois dans le corpus\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
